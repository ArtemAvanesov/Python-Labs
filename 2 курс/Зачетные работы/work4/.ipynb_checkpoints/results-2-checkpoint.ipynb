{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = np.loadtxt('ionosphere.csv', delimiter=';', unpack=False)\n",
    "X = data[:, :34]\n",
    "y = data[:, 34:35]\n",
    "y = y.reshape(351)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "X_train_scaled = X_train\n",
    "X_test_scaled = X_test\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "Lr1 = LogisticRegression(C = 0.6, penalty='l1', solver='liblinear', random_state=1)\n",
    "Lr1.fit(X_train_scaled,y_train)\n",
    "Lr2 = LogisticRegression(C = 0.3, penalty='l2', solver='liblinear', random_state=1)\n",
    "Lr2.fit(X_train_scaled,y_train)\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "linear_svm_l1 = LinearSVC(C = 0.8, penalty=\"l1\", dual=False)\n",
    "linear_svm_l1.fit(X_train_scaled,y_train)\n",
    "linear_svm_l2 = LinearSVC(C = 0.3, penalty=\"l2\", dual=False)\n",
    "linear_svm_l2.fit(X_train_scaled,y_train)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "estimator = KNeighborsClassifier(n_neighbors = 7, metric='minkowski', algorithm='ball_tree')\n",
    "estimator.fit(X_train_scaled, y_train)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "Tree = DecisionTreeClassifier(random_state = 1, max_features=16, max_depth=3, min_samples_leaf=2)\n",
    "Tree.fit(X_train_scaled, y_train)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=10, max_features=10, max_depth=3, min_samples_leaf=1, random_state=1)\n",
    "forest.fit(X_train_scaled, y_train)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(solver=\"lbfgs\", random_state = 1, activation='relu', alpha=0.12, max_iter=22, hidden_layer_sizes=21)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "boosting = GradientBoostingClassifier(random_state = 1, learning_rate=0.2, n_estimators=15, subsample=0.4)\n",
    "boosting.fit(X_train_scaled, y_train)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "MMS = MinMaxScaler(copy=True, feature_range=(0,1))\n",
    "MMS.fit(X_train)\n",
    "X_train_scaled2 = MMS.transform(X_train)\n",
    "X_test_scaled2 = MMS.transform(X_test)\n",
    "multinomialnb = MultinomialNB(fit_prior=True, alpha=0.001)\n",
    "multinomialnb.fit(X_train_scaled2, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVCL1</td>\n",
       "      <td>93.536</td>\n",
       "      <td>88.636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVCL2</td>\n",
       "      <td>93.536</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegressionL1</td>\n",
       "      <td>91.255</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegressionL2</td>\n",
       "      <td>89.734</td>\n",
       "      <td>86.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>82.89</td>\n",
       "      <td>85.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>92.395</td>\n",
       "      <td>92.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>95.817</td>\n",
       "      <td>95.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>98.859</td>\n",
       "      <td>94.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>97.719</td>\n",
       "      <td>97.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>67.681</td>\n",
       "      <td>63.636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       method train_score test_score\n",
       "0                 LinearSVCL1      93.536     88.636\n",
       "1                 LinearSVCL2      93.536       87.5\n",
       "2        LogisticRegressionL1      91.255       87.5\n",
       "3        LogisticRegressionL2      89.734     86.364\n",
       "4        KNeighborsClassifier       82.89     85.227\n",
       "5      DecisionTreeClassifier      92.395     92.045\n",
       "6      RandomForestClassifier      95.817     95.455\n",
       "7               MLPClassifier      98.859     94.318\n",
       "8  GradientBoostingClassifier      97.719     97.727\n",
       "9               MultinomialNB      67.681     63.636"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "params = ['method','train_score', 'test_score']\n",
    "resuts = []\n",
    "resuts.append(['LinearSVCL1', np.around(linear_svm_l1.score(X_train_scaled, y_train)*100, decimals=3), np.around(linear_svm_l1.score(X_test_scaled, y_test)*100, decimals=3)])\n",
    "resuts.append(['LinearSVCL2', np.around(linear_svm_l2.score(X_train_scaled, y_train)*100, decimals=3), np.around(linear_svm_l2.score(X_test_scaled, y_test)*100, decimals=3)])\n",
    "resuts.append(['LogisticRegressionL1', np.around(Lr1.score(X_train_scaled, y_train)*100, decimals=3), np.around(Lr1.score(X_test_scaled, y_test)*100, decimals=3)])\n",
    "resuts.append(['LogisticRegressionL2', np.around(Lr2.score(X_train_scaled, y_train)*100, decimals=3), np.around(Lr2.score(X_test_scaled, y_test)*100, decimals=3)])\n",
    "resuts.append(['KNeighborsClassifier', np.around(estimator.score(X_train_scaled, y_train)*100, decimals=3), np.around(estimator.score(X_test_scaled, y_test)*100, decimals=3)])\n",
    "resuts.append(['DecisionTreeClassifier', np.around(Tree.score(X_train_scaled, y_train)*100, decimals=3), np.around(Tree.score(X_test_scaled, y_test)*100, decimals=3)])\n",
    "resuts.append(['RandomForestClassifier', np.around(forest.score(X_train_scaled, y_train)*100, decimals=3), np.around(forest.score(X_test_scaled, y_test)*100, decimals=3)])\n",
    "resuts.append(['MLPClassifier', np.around(mlp.score(X_train_scaled, y_train)*100, decimals=3), np.around(mlp.score(X_test_scaled, y_test)*100, decimals=3)])\n",
    "resuts.append(['GradientBoostingClassifier', np.around(boosting.score(X_train_scaled, y_train)*100, decimals=3), np.around(boosting.score(X_test_scaled, y_test)*100, decimals=3)])\n",
    "resuts.append(['MultinomialNB', np.around(multinomialnb.score(X_train_scaled2, y_train)*100, decimals=3), np.around(multinomialnb.score(X_test_scaled2, y_test)*100, decimals=3)])\n",
    "\n",
    "np_resuts = np.array(resuts)\n",
    "data_pd = pd.DataFrame(np_resuts)\n",
    "data_pd.columns = params\n",
    "display(data_pd)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_features_importance_cancer(model):\n",
    "#     plt.barh(range(34), model.feature_importances_, align = 'center')\n",
    "#     plt.yticks(np.arange(34), ionosphere.names)\n",
    "#     plt.xlabel(\"Важность признака\")\n",
    "#     plt.ylabel(\"Признак\")\n",
    "# plot_features_importance_cancer(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>y_test</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LogisticRegressionL1(=0)</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LogisticRegressionL2(=0)</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KNeighbors(=0)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DecisionTree(=0)</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RandomForest(=0)</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MLP(=0)</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.963</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.961</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.425</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GradientBoosting(=0)</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MultinomialNB(=0)</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LogisticRegressionL1(=1)</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LogisticRegressionL2(=1)</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KNeighbors(=1)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DecisionTree(=1)</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.059</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.059</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RandomForest(=1)</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.103</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MLP(=1)</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GradientBoosting(=1)</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MultinomialNB(=1)</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0      1      2      3      4      5      6   \\\n",
       "y_test                    0.000  0.000  0.000  1.000  0.000  0.000  0.000   \n",
       "LogisticRegressionL1(=0)  0.732  0.882  0.966  0.875  0.849  0.764  0.648   \n",
       "LogisticRegressionL2(=0)  0.767  0.857  0.944  0.861  0.831  0.762  0.707   \n",
       "KNeighbors(=0)            1.000  1.000  1.000  1.000  1.000  1.000  1.000   \n",
       "DecisionTree(=0)          0.941  0.941  0.941  0.941  0.941  0.941  0.941   \n",
       "RandomForest(=0)          0.828  0.880  0.917  0.917  0.917  0.917  0.864   \n",
       "MLP(=0)                   0.978  0.997  1.000  0.414  0.997  0.998  0.963   \n",
       "GradientBoosting(=0)      0.907  0.966  0.954  0.499  0.956  0.747  0.738   \n",
       "MultinomialNB(=0)         0.672  0.693  0.733  0.662  0.684  0.674  0.670   \n",
       "LogisticRegressionL1(=1)  0.268  0.118  0.034  0.125  0.151  0.236  0.352   \n",
       "LogisticRegressionL2(=1)  0.233  0.143  0.056  0.139  0.169  0.238  0.293   \n",
       "KNeighbors(=1)            0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "DecisionTree(=1)          0.059  0.059  0.059  0.059  0.059  0.059  0.059   \n",
       "RandomForest(=1)          0.172  0.120  0.083  0.083  0.083  0.083  0.136   \n",
       "MLP(=1)                   0.022  0.003  0.000  0.586  0.003  0.002  0.037   \n",
       "GradientBoosting(=1)      0.093  0.034  0.046  0.501  0.044  0.253  0.262   \n",
       "MultinomialNB(=1)         0.328  0.307  0.267  0.338  0.316  0.326  0.330   \n",
       "\n",
       "                             7      8      9   ...     78     79     80  \\\n",
       "y_test                    0.000  0.000  0.000  ...  1.000  0.000  0.000   \n",
       "LogisticRegressionL1(=0)  0.956  0.903  0.929  ...  0.591  0.973  0.959   \n",
       "LogisticRegressionL2(=0)  0.931  0.881  0.890  ...  0.742  0.957  0.955   \n",
       "KNeighbors(=0)            1.000  1.000  1.000  ...  0.429  1.000  1.000   \n",
       "DecisionTree(=0)          0.941  0.941  0.941  ...  0.000  0.941  0.941   \n",
       "RandomForest(=0)          0.917  0.917  0.897  ...  0.000  0.917  0.826   \n",
       "MLP(=0)                   1.000  0.961  1.000  ...  0.024  1.000  0.999   \n",
       "GradientBoosting(=0)      0.954  0.965  0.947  ...  0.158  0.954  0.739   \n",
       "MultinomialNB(=0)         0.712  0.579  0.659  ...  0.718  0.749  0.638   \n",
       "LogisticRegressionL1(=1)  0.044  0.097  0.071  ...  0.409  0.027  0.041   \n",
       "LogisticRegressionL2(=1)  0.069  0.119  0.110  ...  0.258  0.043  0.045   \n",
       "KNeighbors(=1)            0.000  0.000  0.000  ...  0.571  0.000  0.000   \n",
       "DecisionTree(=1)          0.059  0.059  0.059  ...  1.000  0.059  0.059   \n",
       "RandomForest(=1)          0.083  0.083  0.103  ...  1.000  0.083  0.174   \n",
       "MLP(=1)                   0.000  0.039  0.000  ...  0.976  0.000  0.001   \n",
       "GradientBoosting(=1)      0.046  0.035  0.053  ...  0.842  0.046  0.261   \n",
       "MultinomialNB(=1)         0.288  0.421  0.341  ...  0.282  0.251  0.362   \n",
       "\n",
       "                             81     82     83     84     85     86     87  \n",
       "y_test                    0.000  0.000  0.000  0.000  0.000  0.000  1.000  \n",
       "LogisticRegressionL1(=0)  0.438  0.963  0.950  0.922  0.940  0.915  0.019  \n",
       "LogisticRegressionL2(=0)  0.524  0.940  0.920  0.902  0.916  0.891  0.090  \n",
       "KNeighbors(=0)            1.000  1.000  1.000  1.000  1.000  1.000  0.143  \n",
       "DecisionTree(=0)          0.941  0.941  0.941  0.941  0.941  0.941  0.000  \n",
       "RandomForest(=0)          0.710  0.917  0.917  0.917  0.917  0.917  0.003  \n",
       "MLP(=0)                   0.425  1.000  0.999  0.966  0.999  0.999  0.000  \n",
       "GradientBoosting(=0)      0.810  0.954  0.966  0.965  0.979  0.966  0.042  \n",
       "MultinomialNB(=0)         0.639  0.723  0.730  0.571  0.636  0.690  0.550  \n",
       "LogisticRegressionL1(=1)  0.562  0.037  0.050  0.078  0.060  0.085  0.981  \n",
       "LogisticRegressionL2(=1)  0.476  0.060  0.080  0.098  0.084  0.109  0.910  \n",
       "KNeighbors(=1)            0.000  0.000  0.000  0.000  0.000  0.000  0.857  \n",
       "DecisionTree(=1)          0.059  0.059  0.059  0.059  0.059  0.059  1.000  \n",
       "RandomForest(=1)          0.290  0.083  0.083  0.083  0.083  0.083  0.997  \n",
       "MLP(=1)                   0.575  0.000  0.001  0.034  0.001  0.001  1.000  \n",
       "GradientBoosting(=1)      0.190  0.046  0.034  0.035  0.021  0.034  0.958  \n",
       "MultinomialNB(=1)         0.361  0.277  0.270  0.429  0.364  0.310  0.450  \n",
       "\n",
       "[17 rows x 88 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "resuts = []\n",
    "y_test2 = y_test\n",
    "\n",
    "#svc = np.array(np.around(linear_svm_l1.predict_proba(X_test_scaled), decimals=3))\n",
    "#svcc = svc.reshape(2,16)\n",
    "#svc2 = np.array(np.around(linear_svm_l2.predict_proba(X_test_scaled), decimals=3))\n",
    "#svcc2 = svc.reshape(2,16)\n",
    "lr1 = np.array(np.around(Lr1.predict_proba(X_test_scaled), decimals=3))\n",
    "lrr1 = lr1.transpose()\n",
    "lr2 = np.array(np.around(Lr2.predict_proba(X_test_scaled), decimals=3))\n",
    "lrr2 = lr2.transpose()\n",
    "est = np.array(np.around(estimator.predict_proba(X_test_scaled), decimals=3))\n",
    "estt = est.transpose()\n",
    "tre = np.array(np.around(Tree.predict_proba(X_test_scaled), decimals=3))\n",
    "tree = tre.transpose()\n",
    "frt = np.array(np.around(forest.predict_proba(X_test_scaled), decimals=3))\n",
    "frtt = frt.transpose()\n",
    "mlpa = np.array(np.around(mlp.predict_proba(X_test_scaled), decimals=3))\n",
    "mlpaa = mlpa.transpose()\n",
    "bst = np.array(np.around(boosting.predict_proba(X_test_scaled), decimals=3))\n",
    "bstt = bst.transpose()\n",
    "nb = np.array(np.around(multinomialnb.predict_proba(X_test_scaled2), decimals=3))\n",
    "nbb = nb.transpose()\n",
    "\n",
    "resuts.append(y_test2)\n",
    "resuts.append(lrr1[0])\n",
    "resuts.append(lrr2[0])\n",
    "resuts.append(estt[0])\n",
    "resuts.append(tree[0])\n",
    "resuts.append(frtt[0])\n",
    "resuts.append(mlpaa[0])\n",
    "resuts.append(bstt[0])\n",
    "resuts.append(nbb[0])\n",
    "\n",
    "\n",
    "resuts.append(lrr1[1])\n",
    "resuts.append(lrr2[1])\n",
    "resuts.append(estt[1])\n",
    "resuts.append(tree[1])\n",
    "resuts.append(frtt[1])\n",
    "resuts.append(mlpaa[1])\n",
    "resuts.append(bstt[1])\n",
    "resuts.append(nbb[1])\n",
    "\n",
    "\n",
    "np_resuts = np.array(resuts)\n",
    "data_pd = pd.DataFrame(np_resuts, index=['y_test','LogisticRegressionL1(=0)','LogisticRegressionL2(=0)','KNeighbors(=0)','DecisionTree(=0)','RandomForest(=0)', 'MLP(=0)','GradientBoosting(=0)', 'MultinomialNB(=0)',\n",
    "                                                  'LogisticRegressionL1(=1)','LogisticRegressionL2(=1)','KNeighbors(=1)','DecisionTree(=1)','RandomForest(=1)', 'MLP(=1)','GradientBoosting(=1)', 'MultinomialNB(=1)'])\n",
    "#data_pd.columns = params\n",
    "display(data_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "data = np.loadtxt('ionosphere.csv', delimiter=';', unpack=False)\n",
    "X2 = data[:, :34]\n",
    "y2 = data[:, 34:35]\n",
    "y2 = y2.reshape(351)\n",
    "\n",
    "pca = PCA(n_components=13)\n",
    "pca.fit(X2)\n",
    "X_pca = pca.transform(X2)\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_pca, y2, random_state=42)\n",
    "\n",
    "# Нормализация (стандартизация данных)\n",
    "mean_on_train = X_train2.mean(axis = 0)\n",
    "std_on_train = X_train2.std(axis = 0)\n",
    "X_train_scaled2 = (X_train2 - mean_on_train)/std_on_train\n",
    "X_test_scaled2 = (X_test2 - mean_on_train)/std_on_train\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "Lr1_pca = LogisticRegression(C = 0.6, penalty='l1', solver='liblinear', random_state=1)\n",
    "Lr1_pca.fit(X_train_scaled2,y_train2)\n",
    "Lr2_pca = LogisticRegression(C = 0.3, penalty='l2', solver='liblinear', random_state=1)\n",
    "Lr2_pca.fit(X_train_scaled2,y_train2)\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "linear_svm_l1_pca = LinearSVC(C = 0.8, penalty=\"l1\", dual=False)\n",
    "linear_svm_l1_pca.fit(X_train_scaled2,y_train2)\n",
    "linear_svm_l2_pca = LinearSVC(C = 0.3, penalty=\"l2\", dual=False)\n",
    "linear_svm_l2_pca.fit(X_train_scaled2,y_train2)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "estimator_pca = KNeighborsClassifier(n_neighbors = 7, metric='minkowski', algorithm='ball_tree')\n",
    "estimator_pca.fit(X_train_scaled2, y_train2)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "Tree_pca = DecisionTreeClassifier(random_state = 1, max_features=10, max_depth=3, min_samples_leaf=2)\n",
    "Tree_pca.fit(X_train_scaled2, y_train2)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_pca = RandomForestClassifier(n_estimators=10, max_features=10, max_depth=3, min_samples_leaf=1, random_state=1)\n",
    "forest_pca.fit(X_train_scaled2, y_train2)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_pca = MLPClassifier(solver=\"lbfgs\", random_state = 1, activation='relu', alpha=0.12, max_iter=22, hidden_layer_sizes=21)\n",
    "mlp_pca.fit(X_train_scaled2, y_train2)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "boosting_pca = GradientBoostingClassifier(random_state = 1, learning_rate=0.2, n_estimators=15, subsample=0.4)\n",
    "boosting_pca.fit(X_train_scaled2, y_train2)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "MMS_pca = MinMaxScaler(copy=True, feature_range=(0,1))\n",
    "MMS_pca.fit(X_train2)\n",
    "X_train_scaled3 = MMS_pca.transform(X_train2)\n",
    "X_test_scaled3 = MMS_pca.transform(X_test2)\n",
    "multinomialnb_pca = MultinomialNB(fit_prior=True, alpha=0.001)\n",
    "multinomialnb_pca.fit(X_train_scaled3, y_train2)\n",
    "\n",
    "# import mglearn\n",
    "# import matplotlib.pyplot as plt\n",
    "# mglearn.discrete_scatter(X_pca[:,0], X_pca[:,1], y2)\n",
    "# plt.xlabel(\"Компонента_0_pca\")\n",
    "# plt.ylabel(\"Компонента_1_pca\")\n",
    "# plt.legend([\"Класс_0\",\"Класс_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>test_profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVCL1_pca</td>\n",
       "      <td>88.973</td>\n",
       "      <td>89.773</td>\n",
       "      <td>1.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVCL2_pca</td>\n",
       "      <td>88.973</td>\n",
       "      <td>88.636</td>\n",
       "      <td>1.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegressionL1_pca</td>\n",
       "      <td>88.213</td>\n",
       "      <td>89.773</td>\n",
       "      <td>2.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegressionL2_pca</td>\n",
       "      <td>88.973</td>\n",
       "      <td>88.636</td>\n",
       "      <td>2.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier_pca</td>\n",
       "      <td>88.593</td>\n",
       "      <td>88.636</td>\n",
       "      <td>3.409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier_pca</td>\n",
       "      <td>92.395</td>\n",
       "      <td>90.909</td>\n",
       "      <td>-1.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier_pca</td>\n",
       "      <td>95.437</td>\n",
       "      <td>93.182</td>\n",
       "      <td>-2.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>MLPClassifier_pca</td>\n",
       "      <td>99.62</td>\n",
       "      <td>92.045</td>\n",
       "      <td>-2.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier_pca</td>\n",
       "      <td>98.099</td>\n",
       "      <td>94.318</td>\n",
       "      <td>-3.409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>MultinomialNB_pca</td>\n",
       "      <td>64.259</td>\n",
       "      <td>63.636</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           method train_score test_score test_profit\n",
       "0                 LinearSVCL1_pca      88.973     89.773       1.136\n",
       "1                 LinearSVCL2_pca      88.973     88.636       1.136\n",
       "2        LogisticRegressionL1_pca      88.213     89.773       2.273\n",
       "3        LogisticRegressionL2_pca      88.973     88.636       2.273\n",
       "4        KNeighborsClassifier_pca      88.593     88.636       3.409\n",
       "5      DecisionTreeClassifier_pca      92.395     90.909      -1.136\n",
       "6      RandomForestClassifier_pca      95.437     93.182      -2.273\n",
       "7               MLPClassifier_pca       99.62     92.045      -2.273\n",
       "8  GradientBoostingClassifier_pca      98.099     94.318      -3.409\n",
       "9               MultinomialNB_pca      64.259     63.636         0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "params = ['method','train_score', 'test_score', 'test_profit']\n",
    "resuts = []\n",
    "resuts.append(['LinearSVCL1_pca', np.around(linear_svm_l1_pca.score(X_train_scaled2, y_train2)*100, decimals=3), np.around(linear_svm_l1_pca.score(X_test_scaled2, y_test2)*100, decimals=3), np.around(linear_svm_l1_pca.score(X_test_scaled2, y_test2)*100-linear_svm_l1.score(X_test_scaled, y_test)*100, decimals=3)])\n",
    "resuts.append(['LinearSVCL2_pca', np.around(linear_svm_l2_pca.score(X_train_scaled2, y_train2)*100, decimals=3), np.around(linear_svm_l2_pca.score(X_test_scaled2, y_test2)*100, decimals=3), np.around(linear_svm_l2_pca.score(X_test_scaled2, y_test2)*100-linear_svm_l2.score(X_test_scaled, y_test)*100, decimals=3)])\n",
    "resuts.append(['LogisticRegressionL1_pca', np.around(Lr1_pca.score(X_train_scaled2, y_train2)*100, decimals=3), np.around(Lr1_pca.score(X_test_scaled2, y_test2)*100, decimals=3), np.around(Lr1_pca.score(X_test_scaled2, y_test2)*100-Lr1.score(X_test_scaled, y_test)*100, decimals=3)])\n",
    "resuts.append(['LogisticRegressionL2_pca', np.around(Lr2_pca.score(X_train_scaled2, y_train2)*100, decimals=3), np.around(Lr2_pca.score(X_test_scaled2, y_test2)*100, decimals=3), np.around(Lr2_pca.score(X_test_scaled2, y_test2)*100-Lr2.score(X_test_scaled, y_test)*100, decimals=3)])\n",
    "resuts.append(['KNeighborsClassifier_pca', np.around(estimator_pca.score(X_train_scaled2, y_train2)*100, decimals=3), np.around(estimator_pca.score(X_test_scaled2, y_test2)*100, decimals=3), np.around(estimator_pca.score(X_test_scaled2, y_test2)*100-estimator.score(X_test_scaled, y_test)*100, decimals=3)])\n",
    "resuts.append(['DecisionTreeClassifier_pca', np.around(Tree_pca.score(X_train_scaled2, y_train2)*100, decimals=3), np.around(Tree_pca.score(X_test_scaled2, y_test2)*100, decimals=3), np.around(Tree_pca.score(X_test_scaled2, y_test2)*100-Tree.score(X_test_scaled, y_test)*100, decimals=3)])\n",
    "resuts.append(['RandomForestClassifier_pca', np.around(forest_pca.score(X_train_scaled2, y_train2)*100, decimals=3), np.around(forest_pca.score(X_test_scaled2, y_test2)*100, decimals=3), np.around(forest_pca.score(X_test_scaled2, y_test2)*100-forest.score(X_test_scaled, y_test)*100, decimals=3)])\n",
    "resuts.append(['MLPClassifier_pca', np.around(mlp_pca.score(X_train_scaled2, y_train2)*100, decimals=3), np.around(mlp_pca.score(X_test_scaled2, y_test2)*100, decimals=3), np.around(mlp_pca.score(X_test_scaled2, y_test2)*100-mlp.score(X_test_scaled, y_test)*100, decimals=3)])\n",
    "resuts.append(['GradientBoostingClassifier_pca', np.around(boosting_pca.score(X_train_scaled2, y_train2)*100, decimals=3), np.around(boosting_pca.score(X_test_scaled2, y_test2)*100, decimals=3), np.around(boosting_pca.score(X_test_scaled2, y_test2)*100-boosting.score(X_test_scaled, y_test)*100, decimals=3)])\n",
    "resuts.append(['MultinomialNB_pca', np.around(multinomialnb_pca.score(X_train_scaled3, y_train2)*100, decimals=3), np.around(multinomialnb_pca.score(X_test_scaled3, y_test2)*100, decimals=3), np.around(multinomialnb_pca.score(X_test_scaled3, y_test2)*100-multinomialnb_pca.score(X_test_scaled3, y_test2)*100, decimals=3)])\n",
    "\n",
    "np_resuts = np.array(resuts)\n",
    "data_pd = pd.DataFrame(np_resuts)\n",
    "data_pd.columns = params\n",
    "display(data_pd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56  0]\n",
      " [18 14]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1eb7fa6cf60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# y_pred = Lr1_pca.predict(X_test_scaled2)\n",
    "# y_pred = boosting_pca.predict(X_test_scaled2)\n",
    "# y_pred = forest_pca.predict(X_test_scaled2)\n",
    "y_pred = multinomialnb_pca.predict(X_test_scaled2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Построение матрицы путаницы\n",
    "def plot_confusion_matrix(y_true, y_pred, classes, cmap=plt.cm.cubehelix_r):\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title='Confusion matrix',\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, classes=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
      " 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1eb037977f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mglearn\n",
    "import matplotlib.pyplot as plt\n",
    "print(y2)\n",
    "print(y_pred)\n",
    "mglearn.discrete_scatter(X_test2[:,0], X_test2[:,1], y_pred)\n",
    "plt.xlabel(\"Компонента_0_pca\")\n",
    "plt.ylabel(\"Компонента_1_pca\")\n",
    "plt.legend([\"Класс_0\",\"Класс_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>test_profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier_pca</td>\n",
       "      <td>95.437</td>\n",
       "      <td>93.182</td>\n",
       "      <td>-2.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier_pca</td>\n",
       "      <td>99.62</td>\n",
       "      <td>92.045</td>\n",
       "      <td>-2.273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       method train_score test_score test_profit\n",
       "0  RandomForestClassifier_pca      95.437     93.182      -2.273\n",
       "1           MLPClassifier_pca       99.62     92.045      -2.273"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "params = ['method','train_score', 'test_score', 'test_profit']\n",
    "resuts = []\n",
    "resuts.append(['RandomForestClassifier_pca', np.around(forest_pca.score(X_train_scaled2, y_train2)*100, decimals=3), np.around(forest_pca.score(X_test_scaled2, y_test2)*100, decimals=3), np.around(forest_pca.score(X_test_scaled2, y_test2)*100-forest.score(X_test_scaled, y_test)*100, decimals=3)])\n",
    "resuts.append(['MLPClassifier_pca', np.around(mlp_pca.score(X_train_scaled2, y_train2)*100, decimals=3), np.around(mlp_pca.score(X_test_scaled2, y_test2)*100, decimals=3), np.around(mlp_pca.score(X_test_scaled2, y_test2)*100-mlp.score(X_test_scaled, y_test)*100, decimals=3)])\n",
    "\n",
    "np_resuts = np.array(resuts)\n",
    "data_pd = pd.DataFrame(np_resuts)\n",
    "data_pd.columns = params\n",
    "display(data_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>95.817</td>\n",
       "      <td>95.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>98.859</td>\n",
       "      <td>94.318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   method train_score test_score\n",
       "0  RandomForestClassifier      95.817     95.455\n",
       "1           MLPClassifier      98.859     94.318"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "params = ['method','train_score', 'test_score']\n",
    "resuts = []\n",
    "resuts.append(['RandomForestClassifier', np.around(forest.score(X_train_scaled, y_train)*100, decimals=3), np.around(forest.score(X_test_scaled, y_test)*100, decimals=3)])\n",
    "resuts.append(['MLPClassifier', np.around(mlp.score(X_train_scaled, y_train)*100, decimals=3), np.around(mlp.score(X_test_scaled, y_test)*100, decimals=3)])\n",
    "\n",
    "np_resuts = np.array(resuts)\n",
    "data_pd = pd.DataFrame(np_resuts)\n",
    "data_pd.columns = params\n",
    "display(data_pd)\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(random_state=1)\n",
    "forest.fit(X_train_scaled, y_train)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(random_state = 1)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "params = ['method','train_score', 'test_score']\n",
    "resuts = []\n",
    "resuts.append(['RandomForestClassifier', np.around(forest.score(X_train_scaled, y_train)*100, decimals=3), np.around(forest.score(X_test_scaled, y_test)*100, decimals=3)])\n",
    "resuts.append(['MLPClassifier', np.around(mlp.score(X_train_scaled, y_train)*100, decimals=3), np.around(mlp.score(X_test_scaled, y_test)*100, decimals=3)])\n",
    "\n",
    "np_resuts = np.array(resuts)\n",
    "data_pd = pd.DataFrame(np_resuts)\n",
    "data_pd.columns = params\n",
    "display(data_pd)\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
